{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLVQhEMCQZL-"
      },
      "source": [
        "# Employee Compensation Fairness & Market Benchmarking Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UAWgU3NQZMB"
      },
      "source": [
        "## Problem Statement\n",
        "Our objective is to develop a robust machine learning model that accurately predicts optimal employee salary ranges based on internal factors (like experience, education, and role) and external market benchmarks. This model will enable the Human Resources department to ensure competitive and equitable compensation structures, proactively identify and rectify pay disparities, support data-driven salary negotiations for new hires, and optimize overall workforce budgeting for sustainable growth and talent retention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pw_7m1gQZMC"
      },
      "source": [
        "## 1. Importing Libraries\n",
        "We need to import all the necessary libraries that will be used for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "IMIaTbzIQZMD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier # New import for XGBoost\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CIZV0MoQZMF"
      },
      "source": [
        "## 2. Data Loading and Initial Exploration\n",
        "We will use the 'Adult Income Dataset' (adult.csv) from [kaggle](https://www.kaggle.com/datasets/uciml/adult-census-income), which contains various demographic and employment-related features, along with an income bracket (`<=50K` or `>50K`), serving as our target variable for salary range prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVGV9q2TQZMF",
        "outputId": "61d34133-9584-4d15-cb3f-22aee68fb8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the dataset:\n",
            "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
            "0   90         ?   77053       HS-grad              9        Widowed   \n",
            "1   82   Private  132870       HS-grad              9        Widowed   \n",
            "2   66         ?  186061  Some-college             10        Widowed   \n",
            "3   54   Private  140359       7th-8th              4       Divorced   \n",
            "4   41   Private  264663  Some-college             10      Separated   \n",
            "\n",
            "          occupation   relationship   race     sex  capital.gain  \\\n",
            "0                  ?  Not-in-family  White  Female             0   \n",
            "1    Exec-managerial  Not-in-family  White  Female             0   \n",
            "2                  ?      Unmarried  Black  Female             0   \n",
            "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
            "4     Prof-specialty      Own-child  White  Female             0   \n",
            "\n",
            "   capital.loss  hours.per.week native.country income  \n",
            "0          4356              40  United-States  <=50K  \n",
            "1          4356              18  United-States  <=50K  \n",
            "2          4356              40  United-States  <=50K  \n",
            "3          3900              40  United-States  <=50K  \n",
            "4          3900              40  United-States  <=50K  \n",
            "\n",
            "Dataset shape (rows, columns):\n",
            "(32561, 15)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset. Make sure adult.csv is in the correct path or same directory.\n",
        "try:\n",
        "    data = pd.read_csv(\"adult.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: adult.csv not found. Please ensure the file is in the correct directory.\")\n",
        "    # Example for Google Colab if you're still using it and the file is in sample_data\n",
        "    # data = pd.read_csv(\"/content/sample_data/adult.csv\")\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head(5))\n",
        "\n",
        "print(\"\\nDataset shape (rows, columns):\")\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-GLkGFRQZMG"
      },
      "source": [
        "## 3. Finding Null Values and Initial Cleaning\n",
        "We'll check for missing values and handle them, specifically the '?' values in categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmDSj7EZQZMG",
        "outputId": "1d76143e-1ad7-4d57-9804-3aba701072f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values before handling '?' marks:\n",
            "age               0\n",
            "workclass         0\n",
            "fnlwgt            0\n",
            "education         0\n",
            "education.num     0\n",
            "marital.status    0\n",
            "occupation        0\n",
            "relationship      0\n",
            "race              0\n",
            "sex               0\n",
            "capital.gain      0\n",
            "capital.loss      0\n",
            "hours.per.week    0\n",
            "native.country    0\n",
            "income            0\n",
            "dtype: int64\n",
            "\n",
            "Value counts for 'workclass' after handling '?' marks:\n",
            "workclass\n",
            "Private             22696\n",
            "Self-emp-not-inc     2541\n",
            "Local-gov            2093\n",
            "Others               1836\n",
            "State-gov            1298\n",
            "Self-emp-inc         1116\n",
            "Federal-gov           960\n",
            "Without-pay            14\n",
            "Never-worked            7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for 'occupation' after handling '?' marks:\n",
            "occupation\n",
            "Prof-specialty       4140\n",
            "Craft-repair         4099\n",
            "Exec-managerial      4066\n",
            "Adm-clerical         3770\n",
            "Sales                3650\n",
            "Other-service        3295\n",
            "Machine-op-inspct    2002\n",
            "Others               1843\n",
            "Transport-moving     1597\n",
            "Handlers-cleaners    1370\n",
            "Farming-fishing       994\n",
            "Tech-support          928\n",
            "Protective-serv       649\n",
            "Priv-house-serv       149\n",
            "Armed-Forces            9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Missing values before handling '?' marks:\")\n",
        "print(data.isna().sum())\n",
        "\n",
        "# Replace '?' with 'Others' in relevant columns as done in the original notebook\n",
        "data.replace('?', 'Others', inplace=True)\n",
        "\n",
        "print(\"\\nValue counts for 'workclass' after handling '?' marks:\")\n",
        "print(data['workclass'].value_counts())\n",
        "\n",
        "print(\"\\nValue counts for 'occupation' after handling '?' marks:\")\n",
        "print(data['occupation'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brM12OYwQZMH"
      },
      "source": [
        "## 4. Handling Outliers and Data Cleaning by Mutual Understanding\n",
        "Based on common sense and the nature of the data, we'll remove some rows that are less relevant for income prediction (e.g., very young/old ages, non-working individuals, very low education levels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qz3yC9ZQZMI",
        "outputId": "46fbc899-1a75-4f33-ebbf-1663df7f29d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: (32561, 15)\n",
            "Shape after age filtering: (32320, 15)\n",
            "Shape after workclass filtering: (32299, 15)\n",
            "Shape after education filtering: (31758, 15)\n"
          ]
        }
      ],
      "source": [
        "# Age outlier handling (as done in the original notebook)\n",
        "print(\"Original shape:\", data.shape)\n",
        "data = data[(data['age'] <= 75) & (data['age'] >= 17)]\n",
        "print(\"Shape after age filtering:\", data.shape)\n",
        "\n",
        "# Remove 'Without-pay' and 'Never-worked' from 'workclass'\n",
        "data = data[data['workclass'] != 'Without-pay']\n",
        "data = data[data['workclass'] != 'Never-worked']\n",
        "print(\"Shape after workclass filtering:\", data.shape)\n",
        "\n",
        "# Remove very low education categories\n",
        "data = data[data['education'] != '1st-4th']\n",
        "data = data[data['education'] != '5th-6th']\n",
        "data = data[data['education'] != 'Preschool']\n",
        "print(\"Shape after education filtering:\", data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JOpJ5JPQZMK"
      },
      "source": [
        "## 5. Feature Engineering/Selection\n",
        "We'll drop redundant columns. `education` and `education-num` convey similar information; we'll keep the numerical `education-num`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRB5lzWYQZMK",
        "outputId": "de5b7075-6368-4f74-d465-ba208639e00d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns after dropping 'education': ['age', 'workclass', 'fnlwgt', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income']\n"
          ]
        }
      ],
      "source": [
        "data.drop(columns=['education'], inplace=True)\n",
        "print(\"Columns after dropping 'education':\", data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpskxIfmQZMK"
      },
      "source": [
        "## 6. Encoding Categorical Features\n",
        "Machine learning algorithms work with numerical data. We'll convert all categorical (object type) columns into numerical representations using `LabelEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STr_ac50QZML",
        "outputId": "82f1674e-c86e-44bc-9ff6-9b4dd9b50754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved models/workclass_encoder.pkl\n",
            "Saved models/marital.status_encoder.pkl\n",
            "Saved models/occupation_encoder.pkl\n",
            "Saved models/relationship_encoder.pkl\n",
            "Saved models/race_encoder.pkl\n",
            "Saved models/sex_encoder.pkl\n",
            "Saved models/native.country_encoder.pkl\n",
            "\n",
            "Data after Label Encoding categorical features (first 5 rows):\n",
            "   age  workclass  fnlwgt  education.num  marital.status  occupation  \\\n",
            "2   66          2  186061             10               6           8   \n",
            "3   54          3  140359              4               0           6   \n",
            "4   41          3  264663             10               5          10   \n",
            "5   34          3  216864              9               0           7   \n",
            "6   38          3  150601              6               5           0   \n",
            "\n",
            "   relationship  race  sex  capital.gain  capital.loss  hours.per.week  \\\n",
            "2             4     2    0             0          4356              40   \n",
            "3             4     4    0             0          3900              40   \n",
            "4             3     4    0             0          3900              40   \n",
            "5             4     4    0             0          3770              45   \n",
            "6             4     4    1             0          3770              40   \n",
            "\n",
            "   native.country income  \n",
            "2              39  <=50K  \n",
            "3              39  <=50K  \n",
            "4              39  <=50K  \n",
            "5              39  <=50K  \n",
            "6              39  <=50K  \n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Ensure the 'models' directory exists for saving encoders\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "# Identify categorical columns, excluding 'income' as it's the target\n",
        "categorical_input_features = data.select_dtypes(include='object').columns.tolist()\n",
        "if 'income' in categorical_input_features:\n",
        "    categorical_input_features.remove('income')\n",
        "\n",
        "# Store fitted encoders in a dictionary (optional, but good for debugging/verification)\n",
        "fitted_input_encoders = {}\n",
        "\n",
        "# Apply Label Encoding and save each fitted encoder\n",
        "for col in categorical_input_features:\n",
        "    encoder = LabelEncoder()\n",
        "    # Fit and transform the column\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "    # Store the fitted encoder\n",
        "    fitted_input_encoders[col] = encoder\n",
        "    # Save the encoder to a .pkl file\n",
        "    joblib.dump(encoder, f'models/{col}_encoder.pkl')\n",
        "    print(f\"Saved models/{col}_encoder.pkl\")\n",
        "\n",
        "print(\"\\nData after Label Encoding categorical features (first 5 rows):\")\n",
        "print(data.head())\n",
        "\n",
        "# Also, ensure your target variable 'income' LabelEncoder is saved.\n",
        "# This part is usually in section 10, but adding a check here.\n",
        "# Make sure your original notebook also saves the 'le_income' from the target variable.\n",
        "# For example, if you defined 'le_income' and fitted it:\n",
        "# le_income = LabelEncoder()\n",
        "# Y_encoded = le_income.fit_transform(Y) # Assuming Y is your target series\n",
        "# joblib.dump(le_income, 'models/income_label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAjfE-GnQZML"
      },
      "source": [
        "## 7. Splitting Data into X (Independent) and Y (Dependent) Variables\n",
        "We separate the features (X) that will be used for prediction from the target variable (Y), which is 'income' in our case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FqPpYTFQZML",
        "outputId": "5aa682ed-087a-4b4f-bb42-5a005f60e7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (features) head:\n",
            "   age  workclass  fnlwgt  education.num  marital.status  occupation  \\\n",
            "2   66          2  186061             10               6           8   \n",
            "3   54          3  140359              4               0           6   \n",
            "4   41          3  264663             10               5          10   \n",
            "5   34          3  216864              9               0           7   \n",
            "6   38          3  150601              6               5           0   \n",
            "\n",
            "   relationship  race  sex  capital.gain  capital.loss  hours.per.week  \\\n",
            "2             4     2    0             0          4356              40   \n",
            "3             4     4    0             0          3900              40   \n",
            "4             3     4    0             0          3900              40   \n",
            "5             4     4    0             0          3770              45   \n",
            "6             4     4    1             0          3770              40   \n",
            "\n",
            "   native.country  \n",
            "2              39  \n",
            "3              39  \n",
            "4              39  \n",
            "5              39  \n",
            "6              39  \n",
            "\n",
            "Y (target) value counts:\n",
            "income\n",
            "<=50K    23979\n",
            ">50K      7779\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X = data.drop(columns=['income'])\n",
        "Y = data['income']\n",
        "\n",
        "print(\"X (features) head:\")\n",
        "print(X.head())\n",
        "print(\"\\nY (target) value counts:\")\n",
        "print(Y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Woo2I_wQZML"
      },
      "source": [
        "## 8. Feature Scaling\n",
        "Scaling converts all feature values into a uniform range (0 to 1) using `MinMaxScaler`. This is crucial for distance-based algorithms and can benefit others by preventing features with larger values from dominating the learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0m6rky9QZMM",
        "outputId": "454c7837-0897-434b-d027-3267242f2332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of scaled X (features):\n",
            "[[0.84482759 0.33333333 0.11802067 0.5        1.         0.57142857\n",
            "  0.8        0.5        0.         0.         1.         0.39795918\n",
            "  0.95121951]\n",
            " [0.63793103 0.5        0.08698198 0.         0.         0.42857143\n",
            "  0.8        1.         0.         0.         0.8953168  0.39795918\n",
            "  0.95121951]\n",
            " [0.4137931  0.5        0.17140354 0.5        0.83333333 0.71428571\n",
            "  0.6        1.         0.         0.         0.8953168  0.39795918\n",
            "  0.95121951]\n",
            " [0.29310345 0.5        0.13894066 0.41666667 0.         0.5\n",
            "  0.8        1.         0.         0.         0.86547291 0.44897959\n",
            "  0.95121951]\n",
            " [0.36206897 0.5        0.09393787 0.16666667 0.83333333 0.\n",
            "  0.8        1.         1.         0.         0.86547291 0.39795918\n",
            "  0.95121951]]\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"First 5 rows of scaled X (features):\")\n",
        "print(X_scaled[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yU9DG-zQZMM"
      },
      "source": [
        "## 9. Train-Test Split\n",
        "We divide the data into training and testing sets to evaluate the model's performance on unseen data. `stratify=Y` ensures that the proportion of income categories is maintained in both sets, which is important for imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5EcVXqLQZMM",
        "outputId": "3f430751-af92-42d6-a18c-bc4ba4ff5cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of xtrain: (25406, 13)\n",
            "Shape of xtest: (6352, 13)\n",
            "Shape of ytrain: (25406,)\n",
            "Shape of ytest: (6352,)\n"
          ]
        }
      ],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(X_scaled, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "\n",
        "print(\"Shape of xtrain:\", xtrain.shape)\n",
        "print(\"Shape of xtest:\", xtest.shape)\n",
        "print(\"Shape of ytrain:\", ytrain.shape)\n",
        "print(\"Shape of ytest:\", ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgvklqT1QZMM"
      },
      "source": [
        "## 10. Model Training: XGBoost Classifier\n",
        "We'll use an XGBoost Classifier, a powerful gradient boosting algorithm known for its high performance and efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39NLrCvyQZMN",
        "outputId": "74987684-87dc-4d4e-e661-38dc862d2e79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [19:38:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Model trained successfully.\n"
          ]
        }
      ],
      "source": [
        "# XGBoost requires target labels to be 0 and 1. 'income' column has '<=50K' and '>50K'.\n",
        "# We need to encode 'income' column to 0 and 1.\n",
        "le_income = LabelEncoder()\n",
        "ytrain_encoded = le_income.fit_transform(ytrain)\n",
        "ytest_encoded = le_income.transform(ytest)\n",
        "\n",
        "xgb_model = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
        "xgb_model.fit(xtrain, ytrain_encoded)\n",
        "\n",
        "print(\"XGBoost Model trained successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AOyQeCVQZMN"
      },
      "source": [
        "## 11. Model Prediction\n",
        "Making predictions on the test set using the trained XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgGxoGTQZMO",
        "outputId": "49171b32-e409-4493-db4a-73a2a3fc8e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 predictions: ['<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '>50K' '<=50K' '<=50K' '<=50K'\n",
            " '>50K']\n",
            "First 10 actual values: ['<=50K' '<=50K' '>50K' '<=50K' '<=50K' '<=50K' '>50K' '<=50K' '<=50K'\n",
            " '>50K']\n"
          ]
        }
      ],
      "source": [
        "ypred_encoded = xgb_model.predict(xtest)\n",
        "\n",
        "# Decode predictions back to original labels for readability\n",
        "ypred = le_income.inverse_transform(ypred_encoded)\n",
        "\n",
        "print(\"First 10 predictions:\", ypred[:10])\n",
        "print(\"First 10 actual values:\", ytest[:10].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGhKgDHxQZMO"
      },
      "source": [
        "## 12. Model Evaluation\n",
        "Evaluating the model's performance using various metrics: accuracy, classification report (precision, recall, f1-score), and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRz9cAzkQZMO",
        "outputId": "3e44b2d8-2bf5-408c-ffef-f82d1a388d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.8684\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.89      0.94      0.91      4796\n",
            "        >50K       0.77      0.66      0.71      1556\n",
            "\n",
            "    accuracy                           0.87      6352\n",
            "   macro avg       0.83      0.80      0.81      6352\n",
            "weighted avg       0.86      0.87      0.86      6352\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4494  302]\n",
            " [ 534 1022]]\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(ytest, ypred)\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(ytest, ypred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(ytest, ypred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTvcFtv0QZMO"
      },
      "source": [
        "## 13. Hyperparameter Tuning\n",
        "Using `GridSearchCV` to find the best hyperparameters for the XGBoost Classifier, which can further improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RJVWlsIQZMP",
        "outputId": "6f5e20f4-9cec-4164-d95f-1ef2a76957ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV for XGBoost...\n",
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [19:40:52] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters found: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best cross-validation score: 0.8701094551044378\n",
            "\n",
            "Accuracy of the tuned XGBoost model on test set: 0.8758\n",
            "\n",
            "Classification Report of the tuned XGBoost model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.89      0.95      0.92      4796\n",
            "        >50K       0.80      0.65      0.72      1556\n",
            "\n",
            "    accuracy                           0.88      6352\n",
            "   macro avg       0.85      0.80      0.82      6352\n",
            "weighted avg       0.87      0.88      0.87      6352\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],            # Number of boosting rounds\n",
        "    'max_depth': [3, 5, 7],                     # Maximum depth of a tree\n",
        "    'learning_rate': [0.01, 0.1, 0.2],          # Step size shrinkage to prevent overfitting\n",
        "    'subsample': [0.7, 1.0],                    # Subsample ratio of the training instance\n",
        "    'colsample_bytree': [0.7, 1.0]              # Subsample ratio of columns when constructing each tree\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# Use ytrain_encoded for GridSearchCV target\n",
        "grid_search = GridSearchCV(estimator=XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=2,\n",
        "                           scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "print(\"Starting GridSearchCV for XGBoost...\")\n",
        "grid_search.fit(xtrain, ytrain_encoded)\n",
        "\n",
        "print(\"\\nBest parameters found:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "y_pred_tuned_encoded = best_xgb_model.predict(xtest)\n",
        "\n",
        "# Decode predictions back to original labels\n",
        "y_pred_tuned = le_income.inverse_transform(y_pred_tuned_encoded)\n",
        "\n",
        "tuned_accuracy = accuracy_score(ytest, y_pred_tuned)\n",
        "\n",
        "print(f\"\\nAccuracy of the tuned XGBoost model on test set: {tuned_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report of the tuned XGBoost model:\")\n",
        "print(classification_report(ytest, y_pred_tuned))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8lUgtAQZMP"
      },
      "source": [
        "## Next Steps & Deployment\n",
        "After finalizing our model, we can save the `best_xgb_model`, `scaler`, and importantly, the `le_income` LabelEncoder using `joblib` or `pickle`.\n",
        "Then, our Streamlit application (`app.py`) will load these saved objects to make predictions based on user input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHQPf7CNQZMP",
        "outputId": "a4d2a7d7-740b-4900-a5bc-73eb9809dc3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained XGBoost model saved successfully to models/best_salary_predictor_xgb_model.pkl\n",
            "MinMaxScaler saved successfully to models/minmax_scaler.pkl\n",
            "Income LabelEncoder saved successfully to models/income_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create the 'models' directory if it doesn't exist\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "# Save the best trained XGBoost model\n",
        "joblib.dump(best_xgb_model, 'models/best_salary_predictor_xgb_model.pkl')\n",
        "print(\"Trained XGBoost model saved successfully to models/best_salary_predictor_xgb_model.pkl\")\n",
        "\n",
        "# Save the MinMaxScaler\n",
        "joblib.dump(scaler, 'models/minmax_scaler.pkl')\n",
        "print(\"MinMaxScaler saved successfully to models/minmax_scaler.pkl\")\n",
        "\n",
        "# Save the LabelEncoder for the income target variable\n",
        "# This is crucial for decoding predictions in the deployed app\n",
        "joblib.dump(le_income, 'models/income_label_encoder.pkl')\n",
        "print(\"Income LabelEncoder saved successfully to models/income_label_encoder.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
